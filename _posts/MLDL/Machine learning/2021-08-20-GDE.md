---

layout: post

title: "Gaussian Density Estimation"

date: 2021-08-21 00:00:07

categories: [ML/DL/Machine Learning]

description:

image: /img/GDE.png

published: True

canonical_url:

tags: [Machine Learning, Anomaly Detection, Gaussian Density Estimation, Mixture of Gaussian Density Estimation, Kernel Density Estimation, Gauss & MoG, 이상치 탐지]

---

> 이 내용은 고려대학교 강필성 교수님의 Business Analytics 수업을 보고 정리한 것입니다.
>
> 아래 이미지 클릭 시 강의 영상 Youtube URL로 넘어갑니다.
>
>[![03-2 Anomaly Detection - Gauss & MoG
](https://img.youtube.com/vi/kKZM8bxwQbA/mqdefault.jpg)](https://www.youtube.com/watch?v=kKZM8bxwQbA&list=PLetSlH8YjIfWMdw9AuLR5ybkVvGcoG2EW&index=15)

# (Mixture of) Gaussian Density Estimation

## 1. Density-based Novelty Detection

- 목적
    - 현재 주어진 데이터를 활용해서 normal 데이터가 가지고 있는 분포 추정
    - 추정된 분포를 통해서 새로운 객체를 통해서 normal인지 abnormal인지 판단

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled.png' width='200'> <img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 1.png' width='400'>

## 2. Gaussian Density Estimation

- 가정 : 관측치들은 하나의 Gassian distribution으로 부터 샘플링(생성)되었다.
- 수 많은 데이터로 부터 $$\mu$$와 $$\sum$$를 찾아야 한다.

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 2.png' width='600'>

### ✓ 장점

- 데이터 변수의 범위에 덜 민감하다. Robust하다.

    covariance matrix의 역행렬을 구해주기 때문에 변수의 측정 단위가 영향을 끼치지 않는다.

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 3.png' width='400'>

- Optimal threshold를 분석적으로 계산 가능

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 4.png' width='300'>

### ✓ 계산

- Parameter estimation : $$\mu$$, $$\sigma^2$$
- i.i.d를 가정하고 $$\mu, \sigma^2$$이 주어졌을 때 각 객체가 생성될 확률을 모두 곱한 것이 likelihood
- 로그 함수는 단순 증가 함수이기 때문에 $$L$$을 최대화 하는 것과 $$Log\;L$$을 최대화 하는 것은 동치

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 5.png' width='400'>

- Maxium likelihood estimation ($$\gamma=1/\sigma^2$$)

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 6.png' width='600'>

따라서

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 7.png' width='400'>

### ✓ Shape of Gaussian distribution

Covariance matrix는 변수의 갯수만큼 차원을 갖는 square matrix이기 때문에, Covariance matrix를 어떻게 처리하냐에 따라서 추정되는 분포의 모양이 다르다.

- Spherical

Lower, upper triangle이 모두 0 , 모든 변수가 동일한 분산을 가지고 있다고 가정, 아까 가정과는 다르게 normalize를 진행하고 각각의 변수들이 통계적으로 독립이라고 가정

축과 수직이면서 원의 형태

가장 엄격한 가정

$$\sum  =\sigma^2\begin{bmatrix}1&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&1\end{bmatrix}$$

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 8.png' width='500'>

- Diagonal

각각의 변수는 독립을 가정하는 것은 동일, 개별적인 변수들의 분산은 다르다라고 가정

여전히 축에 수직인 장축과 단축을 기준으로 표현되지만 spherical과는 다르게 타원이 될 수 있다.

$$\sum  =\begin{bmatrix}\sigma_1^2&\cdots&0\\\vdots&\ddots&\vdots\\0&\cdots&\sigma_d^2\end{bmatrix}$$

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 9.png' width='500'>

- Full

모든 가정을 완화. 각각의 변수들이 어느정도 상관관계가 있다.

장축과 단축이 축과 수직하지 않다.

데이터가 충분히 많고, covariance matrix가 non-singular matrix라면 full을 쓰는 것이 맞으나, 현실상에서  noise의 존재나, 처리할 수 없는 데이터 상의 변동성으로 인해 잘 맞지 않는 경우 존재. 따라서 full과 spherical의 중간인 diagonal을 사용하는 것이 합리적인 대안이라고 교수님 생각

$$\sum  =\begin{bmatrix}\sigma_{11}&\cdots&\sigma_{1d}\\\vdots&\ddots&\vdots\\\sigma_{d1}&\cdots&\sigma_{dd}\end{bmatrix}$$

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 10.png' width='500'>

## 3. Mixture of Gaussian Density Estimation

- Gaussian Density Estimation의 경우 가정이 매우 엄격하다. 모든 데이터가 하나의 gaussian 분포로 부터 생성되었다고 가정한다.(unimodal & convex)
- multi-modal로 완화한 것으 mixture of gaussian density estimation
- 여러개의 nomal distribution의 선형 결합으로 표현
- single gaussian distribution보다 dias가 적은 정확한 추정을 할 수 있지만, 추정을 위해 더 많은 데이터를 필요
- Parameter estimation : $$\mu$$, $$\sigma$$,$$w$$ ($$3\times k$$개, $$k$$도 몇 개가 좋을지 찾아야함)

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 11.png' width='500'>

### ✓ Components of MoG

- 어떤 객체가 nomal class에 속할 확률

    각각의 개별적인 gaussian 분포에 대한 likelihood를 계산하고, 개별 gaussian의 가중치를 곱해서 전부 더해준 값

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 12.png' width='300'>

- 각 gaussian model의 distribution

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 13.png' width='600'>

### ✓ Expectation-Maximization Algorithm

- E-Step : parameter의 현재 추정값이 주어지면 조건부 확률을 계산

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 14.png' width='500'>

- M-Step : E-Step에서 찾은 expected likelihood를 최대화하도록 parameter를 업데이트
    - Mixture weight

        <img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 15.png' width='400'>

    - Means and variances

        <img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 16.png' width='600'>

### ✓ shape of MoG

<img src='/img/(Mixture of) Gaussian Density Estimation 097659eea3e445bc90174da7b8fb3358/Untitled 17.png' width='600'>

Full이 그림상 가장 좋아보이지만, covariance matrix가 non-singular일 때만 유용한데, 현실 데이터에서는 covariance matrix의 역행렬을 구하는게 singularity가 발생해서 안되는 경우가 상당하다.  

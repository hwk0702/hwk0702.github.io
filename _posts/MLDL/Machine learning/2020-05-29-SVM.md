---

layout: post

title: "서포트 벡터 머신"

date: 2020-06-01 10:26:07

categories: [ML/DL/Machine Learning]

description:

image: /img/svm1.png

published: true

canonical_url:

---

> 이 내용은 핸즈온 머신러닝 2판 책을 보고 정리한 것 입니다.
>
> <img src='http://image.yes24.com/goods/89959711/800x0' width='150'>

서포트 벡터 머신 (Support Vector Machine, SVM)
----------------------------------------------

-	선형이나 비선형 분류, 회귀, 이상치 탐색에도 사용할 수 있는 다목적 머신러닝 모델
-	복잡한 분류 문제에 잘 들어맞으며 작거나 중간 크기의 데이터셋에 적합
-	확률을 직접 계산하지 않고 데이터가 어떤 '경계선'을 넘는지 넘지 않는지 검사하여 분류한다.
-	종속변수를 두 개 그룹으로 구분하여 중심선을 구하여, 2개 이상의 그룹으로 구분 될 경우에만 각 그룹별로 모두 중심선을 구한 후, 향후 판별시에 여러 중심선을 함께 고려하여 연산한다.
-	특성의 스케일에 민감하다.

| 장점 | 단점|
|----|----|
| * 구조적이며 매번 수행해도 결과가 어느정도 비슷함 <br> * 경계선 근처의 데이터들만 고려하기 때문에 모델이 가볍고 노이즈에 강함 | * 구체적 확률값 구하기 어려움 |

---

#### 1. 선형 SVM 분류

-	라지 마진 분류: 결정 경계가 클래스를 잘 나누고 제일 가까운 훈련 샘플로부터 가능한 멀리 떨어져 있는 직선일 때

<img src='/img/svm2.png' width='400'>

#### 2. 소프트 마진 분류

-	하드 마진 분류: 모든 샘플이 결정 경계 바깥쪽으로 올바르게 분류 되어 있는 경우
-	하드 마진 분류의 문제점: 데이터가 선형적으로 구분될 수 있어야 제대로 작동하며, 이상치에 민감하다.  

<img src='/img/svm3.png' width='400'>

- 소프트 마진 분류: 도로의 폭을 가능한 넓게 유지하는 것과 마진 오류 사이에 적절한 균형을 잡는 것
- 하이퍼파라미터 C를 조정. 낮게 설정하면 도로의 폭이 넓어지는 대신 마진 오류가 증가하고, 높게 설정하면 도로의 폭이 좁아지는 대신 마진 오류가 적어진다.
- 일반적으로 마진 오류가 적은 것이 좋다.

<img src='/img/svm4.png' width='400'>

#### 3. 비선형 SVM 분류

- 비선형 데이터셋에 다항 특성과 같은 특성을 더 추가하여 선형적으로 구분되는 데이터셋으로 변경
- 간단하고 모든 머신러닝 알고리즘에서 잘 작동
- 낮은 차수의 다항식은 매우 복잡한 데이터셋을 잘 표현하지 못하고 높은 차수의 다항식은 많은 특성을 추가하므로 모델을 느리게 만든다.

<img src='/img/svm5.png' width='400'> 

##### 3.1. 다항식 커널

- 커널 트릭: 실제로 특성을 추가하지 않으면서 다항식 특성을 많이 추가한 것과 같은 결과를 얻을 수 있다.

<img src='/img/svm6.png' width='400'> 

##### 3.2. 유사도 특성

- 비선형 특성을 다루는 다른 기법으로 각 샘플이 특정 랜드마크와 얼마나 닮았는지 측정하는 유사도 함수로 계산한 특성을 추가하는 것
- 예: 

랜드마크 $$x_1=-2$$와 $$x_1=1$$이라 하고, $$\gamma=0.3$$인 가우시안 방사 기저 함수(RBF)를 유사도 함수라고 정의하는 경우

가우시안 RBF : $$\phi_{\gamma}(\mathbf{x},l)=exp(-\gamma{\Vert \mathbf{x}-l \Vert}^2)$$

$$x_1=-1$$인 샘플의 경우 새로 만들어지는 특성 $x_2=exp(-0.3*1^2)\approx 0.74$, $x_3=exp(-0.3*2^2)\approx 0.30$이다.

<img src='/img/svm7.png' width='400'> 

- 랜드마크를 설정하는 방법: 데이터셋에 있는 모든 샘플 위치에 랜드마크를 설정하는 것 (차원이 매우 커지고 변환된 훈련 세트가 선형적으로 구분될 가능성이 높다.)

- 단점: 훈련 세트에 있는 n개의 특성을 가진 m개의 샘플이 m개의 특성을 가진 m개의 샘플로 변환된다는 것, 훈련 세트가 매우 클 경우 동일한 크기의 특성이 만들어진다.

##### 3.3. 가우시안 RBF 커널

- 유사도 특성을 많이 추가하는 것과 같은 비슷한 결과
- gamma를 증가시키면 종 모양 그래프가 좁아져 각 샘플의 영향 범위가 작아진다. 반대로 gamma를 작게하면 넓은 종 모양 그래프를 만들며 샘플이 넓은 범위에 걸쳐 영향을 준다. 

<img src='/img/svm8.png' width='400'> 

- 먼저 선형 커널을 시도(특히 훈련 세트가 아주 크거나 특성 수가 많을 경우), 훈련 세트가 너무 크지 않다면 가우시안 RBF 커널 시도

##### 3.4 계산 복잡도

|파이썬 클래스|시간 복잡도|외부 메모리 학습 지원|스케일 조정의 필요성|커널 트릭|
|---------|----------|-----------|----------|----------|
|LinearSVC| $$O(m*n)$$ |아니오|예|아니오|
|SGDClassifier| $$O(m*n)$$ |예|예|아니오|
|SVC| $$O(m^2*n)~O(m^3*n)$$|아니오|예|예|